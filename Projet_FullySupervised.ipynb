{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RandAugment"
      ],
      "metadata": {
        "id": "rHIndKj4l42E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall --yes imgaug\n",
        "!pip install imgaug==0.4.0"
      ],
      "metadata": {
        "id": "DpthVZXxne9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imgaug.augmenters as iaa\n",
        "aug = iaa.RandAugment(n=2, m=9)\n",
        "\n",
        "def randaugment(img):\n",
        "  return aug(images=img)"
      ],
      "metadata": {
        "id": "b_WONLK3l8dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des données"
      ],
      "metadata": {
        "id": "7qHhlS_eds_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLt8kWC1kN6g"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/axelcarlier/projsemisup.git\n",
        "path = \"./projsemisup/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CLASSES = os.listdir(path + 'Lab/')\n",
        "print(CLASSES)"
      ],
      "metadata": {
        "id": "u1eKpFsOt6Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 64"
      ],
      "metadata": {
        "id": "C8Ry0cSc2kn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_semisup_data(path, classes, image_size=64):\n",
        "\n",
        "  file_path_lab = os.listdir(path + 'Lab/')\n",
        "  nb_lab = 360\n",
        "  # Initialise les structures de données\n",
        "  x_lab = np.zeros((nb_lab, image_size, image_size, 3))\n",
        "  y_lab = np.zeros((nb_lab, 1))\n",
        "  i = 0\n",
        "  for c in file_path_lab:\n",
        "\n",
        "    class_label = classes.index(c)\n",
        "    list_images = os.listdir(path + 'Lab/' + c + '/')\n",
        "\n",
        "    for img_name in list_images:\n",
        "      # Lecture de l'image\n",
        "      img = Image.open(path + 'Lab/' + c + '/' + img_name)\n",
        "      # Mise à l'échelle de l'image\n",
        "      img = img.resize((image_size,image_size), Image.ANTIALIAS)\n",
        "      img = img.convert('RGB')\n",
        "      # Remplissage de la variable x\n",
        "      x_lab[i] = np.asarray(img)\n",
        "      y_lab[i] = class_label\n",
        "      i = i + 1\n",
        "\n",
        "\n",
        "  file_path_test = os.listdir(path + 'Test/')\n",
        "  nb_test = 1800\n",
        "  # Initialise les structures de données\n",
        "  x_test = np.zeros((nb_test, image_size, image_size, 3))\n",
        "  y_test = np.zeros((nb_test, 1))\n",
        "  i = 0\n",
        "  for c in file_path_test:\n",
        "\n",
        "    class_label = classes.index(c)\n",
        "    list_images = os.listdir(path + 'Test/' + c + '/')\n",
        "\n",
        "    for img_name in list_images:\n",
        "      # Lecture de l'image\n",
        "      img = Image.open(path + 'Test/' + c + '/' + img_name)\n",
        "      # Mise à l'échelle de l'image\n",
        "      img = img.resize((image_size,image_size), Image.ANTIALIAS)\n",
        "      img = img.convert('RGB')\n",
        "      # Remplissage de la variable x\n",
        "      x_test[i] = np.asarray(img)\n",
        "      y_test[i] = class_label\n",
        "      i = i + 1\n",
        "\n",
        "\n",
        "  return x_lab, y_lab, x_test, y_test\n",
        "\n",
        "\n",
        "x_lab, y_lab, x_test, y_test = load_semisup_data(path, CLASSES, image_size=IMAGE_SIZE)\n"
      ],
      "metadata": {
        "id": "kdho3Bt4kiG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_lab.shape, y_lab.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "Hukak8wV-6Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Randomisation des indices et affichage de 9 images aléatoires de la base d'apprentissage\n",
        "indices = np.arange(x_lab.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.title(CLASSES[int(y_lab[indices[i]])])\n",
        "    plt.imshow(x_lab[indices[i]]/255)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RSY6mdTAJI5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Randomisation des indices et affichage de 9 images aléatoires de la base de test\n",
        "indices = np.arange(x_test.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.title(CLASSES[int(y_test[indices[i]])])\n",
        "    plt.imshow(x_test[indices[i]]/255)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OuWWOv0eyT8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def create_model(image_size=64):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(64,(3,3),input_shape=(image_size,image_size,3),activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,activation='relu'))\n",
        "  model.add(Dense(95,activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "l1TxosRBfG-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apprentissage supervisé avec augmentation"
      ],
      "metadata": {
        "id": "cvYLSbtsd699"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import math\n",
        "\n",
        "x_train_lab = x_lab\n",
        "y_train_lab = y_lab\n",
        "\n",
        "# Hyperparamètres de l'apprentissage\n",
        "epochs = 200\n",
        "batch_size = 16\n",
        "steps_per_epoch = math.floor(x_train_lab.shape[0]/batch_size)\n",
        "\n",
        "model = create_model(image_size=IMAGE_SIZE)\n",
        "\n",
        "# Instanciation d'un optimiseur et d'une fonction de coût.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# Préparation des métriques pour le suivi de la performance du modèle.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Indices de l'ensemble labellisé\n",
        "indices = np.arange(x_train_lab.shape[0])\n",
        "\n",
        "# Boucle sur les epochs\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  # A chaque nouvelle epoch, on randomise les indices de l'ensemble labellisé\n",
        "  np.random.shuffle(indices) \n",
        "\n",
        "  # Et on recommence à cumuler la loss\n",
        "  cum_loss_value = 0\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "\n",
        "    # Sélection des données du prochain batch\n",
        "    x_batch = x_train_lab[indices[step*batch_size:(step+1)*batch_size]]\n",
        "    y_batch = y_train_lab[indices[step*batch_size:(step+1)*batch_size]]\n",
        "\n",
        "    # Augmentation puis des données\n",
        "    x_batch_augment = randaugment(x_batch.astype('uint8'))\n",
        "    x_batch_augment = x_batch_augment.astype('float')/255\n",
        "\n",
        "    # Etape nécessaire pour comparer y_batch à la sortie du réseau\n",
        "    y_batch = np.expand_dims(y_batch, 1)\n",
        "\n",
        "    # Les opérations effectuées par le modèle dans ce bloc sont suivies et permettront\n",
        "    # la différentiation automatique.\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Application du réseau aux données d'entrée\n",
        "      y_pred = model(x_batch_augment, training=True)  # Logits for this minibatch\n",
        "\n",
        "      # Calcul de la fonction de perte sur ce batch\n",
        "      loss_value = loss_fn(y_batch, y_pred)\n",
        "\n",
        "      # Calcul des gradients par différentiation automatique\n",
        "      grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\n",
        "      # Réalisation d'une itération de la descente de gradient (mise à jour des paramètres du réseau)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "      # Mise à jour de la métrique\n",
        "      train_acc_metric.update_state(y_batch, y_pred)\n",
        "\n",
        "      cum_loss_value = cum_loss_value + loss_value\n",
        "\n",
        "  # Calcul de la précision à la fin de l'epoch\n",
        "  train_acc = train_acc_metric.result()\n",
        "\n",
        "  if epoch%5 == 0:\n",
        "    # Calcul de la précision sur l'ensemble de test à la fin de l'epoch, toutes les 5 epochs\n",
        "    test_logits = model(x_test/255, training=False)\n",
        "    test_acc_metric.update_state(np.expand_dims(y_test, 1), test_logits)\n",
        "    test_acc = test_acc_metric.result()\n",
        "\n",
        "    print(\"Epoch %4d : Loss : %.4f, Acc : %.4f, Test Acc : %.4f\" % (epoch, float(cum_loss_value/steps_per_epoch), float(train_acc), float(test_acc)))\n",
        "\n",
        "  else:\n",
        "    print(\"Epoch %4d : Loss : %.4f, Acc : %.4f\" % (epoch, float(cum_loss_value/steps_per_epoch), float(train_acc)))\n",
        "\n",
        "\n",
        "  # Remise à zéro des métriques pour la prochaine epoch\n",
        "  train_acc_metric.reset_states()\n",
        "  test_acc_metric.reset_states()      "
      ],
      "metadata": {
        "id": "k2_zbqvDd8tm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}